#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sun Oct 15 19:03:06 2023

@author: sealight
"""
d_allVisFigInfo = dict()
d_allVisFigInfo['fig1']={'text':'This specific imaging technique is commonly employed to assess the distinguishability between positive and negative samples. The overall presence of well-defined classification boundaries between the two classes within the graphical representation indicates the clear separability of the associated features. Furthermore, this distinct separability contributes significantly to the high recognition performance achieved by your algorithm. <br>Note: RadViz, an advanced algorithm for multivariate data visualization, distributes each feature dimension uniformly along the circumference of a circle. Subsequently, data points are plotted within the circle, with their values normalized along the axes extending from the center to each arc. This mechanism allows for the representation of numerous dimensions within the visualization, thereby expanding its dimensionality.'}
d_allVisFigInfo['fig2']={'text':'The presented graph illustrates the 15 most salient features crucial for class recognition within the scope of this particular recognition task. <br> Note: The algorithm assesses individual features or pairs of features using diverse metrics that assign scores on the [-1, 1] or [0, 1] scale, subsequently enabling their ranking. Similar to SPLOMs (Scatterplot Matrices), these scores are visualized within a lower-left triangle heatmap, facilitating the identification of patterns among feature pairs for subsequent analysis. By default, the Shapiro-Wilk algorithm is employed to evaluate the normality of feature distribution. A barplot is then generated to display the relative ranks of each feature.'}
d_allVisFigInfo['fig3']={'text':'This graph portrays the heatmap depicting the relationships among the top 15 significant features. <br> Note: A two-dimensional feature ranking method is employed, which evaluates pairs of features simultaneously, considering joint plot analysis. The pairs are ranked based on their scores and visualized in the lower left triangle of a feature co-occurrence matrix. The Pearson correlation score is used by default to reveal collinear relationships.'}
d_allVisFigInfo['fig4']={'text':'The parallel coordinate chart plots all the data from the csv file on a single graph, enabling simultaneous visualization of multiple dimensions. This facilitates the observation of clusters of instances that share similar classes and allows identification of features with high variance or distinct distributions. <br> Note: Parallel coordinates is a multidimensional feature visualization technique where each feature is replicated horizontally, creating a vertical axis for each. Instances are represented as line segments that connect each vertical axis to the corresponding value location along the segment. Consequently, numerous dimensions can be visualized at once, and theoretically, an infinite number of dimensions can be displayed with sufficient horizontal space (e.g., in a scrolling window). <br>This method is employed to identify clusters of instances with similar classes and to identify features with high variance or differing distributions. We can observe this visualization technique in action after loading our occupancy classification dataset.'}
d_allVisFigInfo['fig5']={'text':'This plot is commonly employed to assess the distinguishability between positive and negative samples. <br>The PCA Decomposition visualizer utilizes principal component analysis (PCA) to reduce high-dimensional data into two or three dimensions, enabling the plotting of each instance in a scatter plot. The utilization of PCA allows the projected dataset to be analyzed along axes of principal variation, aiding in the interpretation of whether spherical distance metrics can be effectively employed.'}
d_allVisFigInfo['fig6']={'text':'This plot is frequently employed to examine the distinguishability between positive and negative samples.<br>The Manifold visualizer, based on the Isomap algorithm, offers high-dimensional visualization by utilizing manifold learning techniques to embed instances described by numerous dimensions into a two-dimensional space. This enables the creation of a scatter plot that reveals latent structures in the data. <br>In contrast to decomposition methods such as PCA and SVD, manifold approaches typically employ nearest-neighbors methods for embedding, enabling the capture of non-linear structures that would otherwise be lost. Subsequently, the resulting projections can be analyzed for noise and separability, providing insights into the potential creation of a decision space within the data.'}
d_allVisFigInfo['fig7']={'text':'The scatter plot of all samples generated through the t-SNE algorithm is frequently employed to assess the distinguishability between positive and negative samples.<br>The Manifold visualizer, employing the t-SNE algorithm, facilitates high-dimensional visualization by utilizing manifold learning techniques to embed instances described by multiple dimensions into a two-dimensional space. This allows for the creation of a scatter plot that reveals latent structures in the data. <br>In contrast to decomposition methods like PCA and SVD, manifold approaches typically utilize nearest-neighbor methods for embedding, enabling the capture of non-linear structures that would otherwise be lost. The resulting projections can be subsequently analyzed for noise and separability, providing insights into the possibility of creating a decision space within the data.'}
d_allVisFigInfo['fig8']={'text':'The classification report visualizer exhibits the precision, recall, F1, and support scores of the model. <br>To facilitate easier interpretation and problem identification, the report combines numerical scores with a color-coded heatmap. <br>The heatmaps are confined within the range of (0.0, 1.0), enabling straightforward comparison of classification models across various reports.'}
d_allVisFigInfo['fig9']={'text':'The confusion matrix presents a matrix-based summary of dataset records, categorizing them based on two criteria: true category and classification model prediction. This matrix provides an intuitive indication of the model\'s performance shortcomings, highlighting the types of samples where the model exhibits subpar performance.'}
d_allVisFigInfo['fig10']={'text':'ROC-AUC curves serve as performance indicators for classification problems across different threshold settings. The ROC curve represents the probability curve, while the AUC measures the level of separability, indicating the model\'s ability to distinguish between classes. <br>A steeper ROC curve is indicative of better performance, with an ideal value of 1, forming a square, while a random guess yields a value of 0.5. Thus, the average AUC value falls between 0.5 and 1. <br>A higher AUC signifies a superior ability of the model to predict 0 as 0 and 1 as 1.'}
d_allVisFigInfo['fig11']={'text':'Precision is computed as the ratio of true positive classifications to the total number of positive classifications made, encompassing both true positives and false positives. Recall, on the other hand, is calculated as the ratio of true positive classifications to the total number of positive classifications that should have been made, incorporating both true positives and false negatives.<br>A precision-recall (PR) curve is a graphical representation wherein precision values are plotted on the y-axis and recall values are plotted on the x-axis. Consequently, the y-axis represents TP/(TP+FP), while the x-axis represents TP/(TP+FN).<br>The PR curve facilitates the observation of changes in precision and recall throughout various thresholds. Furthermore, it aids in the selection of a reasonable threshold value.'}
d_allVisFigInfo['fig12']={'text':'The Yellowbrick ClassPredictionError plot offers a distinct approach to analyzing classification models, complementing more common tools such as the Confusion Matrix and Classification Report. Comparable to the Classification Report, this plot illustrates the support (i.e., number of training samples) for each class within the fitted classification model through a stacked bar chart. Each bar is further divided to depict the proportion of predictions, including false negatives and false positives, resembling the functionality of a Confusion Matrix. By employing the ClassPredictionError plot, one can visually identify challenging classes for the classifier and, more significantly, gain insights into the specific incorrect predictions made for each class. Such analysis often facilitates a comprehensive understanding of the strengths and weaknesses of different models, as well as the unique challenges inherent in the dataset.<br>The class prediction error chart provides a rapid assessment of the classifier\'s performance regarding accurate class prediction.'}
d_allVisFigInfo['fig13']={'text':'The discrimination threshold refers to the probability or score at which the positive class is favored over the negative class. Typically, the threshold is set to achieve a balance between cases, often at 0.5 or a 50% probability. However, this threshold may not always be optimal, as there is often an inverse relationship between precision and recall concerning the discrimination threshold. By adjusting the threshold of the classifier, it becomes possible to fine-tune the F1 score, which is the harmonic mean of precision and recall, to achieve the best fit or to optimize the classifier\'s behavior based on the specific application. Several metrics are considered when tuning classifiers: <ol><li>Precision: </li>Increasing precision reduces the number of false positives, making it crucial to optimize this metric when the cost of special treatment is high, such as the potential waste of time in fraud prevention or the risk of missing an important email.<li>Recall: </li>Enhancing recall minimizes the likelihood of missing positive instances, and thus, this metric should be optimized when it is vital to capture positive cases, even at the cost of more false positives.<li>F1 Score: </li>The F1 score represents the harmonic mean between precision and recall. The fbeta parameter allows for the determination of the relative weight of precision and recall when calculating this metric, typically set to 1 or F1 by default. Optimizing this metric achieves the best trade-off between precision and recall.<li>Queue Rate:</li> The "queue" refers to the spam folder or the inbox of the fraud investigation desk. This metric depicts the percentage of instances that require review. If the cost of review is high, such as in fraud prevention, minimizing the queue rate becomes imperative to align with business requirements. Conversely, if the cost is low, such as in a spam filter, optimizing the queue rate ensures the cleanliness of the inbox.</ol>'}
d_allVisFigInfo['fig14']={'text':'This figure displays the significant features identified by the provided classifier across all samples. By inputting a matrix of SHAP values into the bar plot function, a global feature importance plot is generated. In this plot, the global importance of each feature is determined by calculating the mean absolute value across all the given samples.<br>It is important to note that the importance value is computed based on the Shapley value.'}
d_allVisFigInfo['fig15']={'text':'We employed the designated classifier to perform classification on the test samples according to the assigned class labels. By doing so, we identified the top 14 features that exerted the most significant influence on the prediction of sample classes in this recognition task. The visualization samples you have set can be located in the software window under "5..." by entering the corresponding sample number. Additionally, all the raw values of the supported samples can be found in the "interpReport" directory of this project, specifically in a file named "rsmpData_xx". The file names are distinguished by the time stamp (xx) to indicate different tasks.'}
d_allVisFigInfo['fig16']={'text':'This figure depicts the Shapley value of each feature across all samples, offering insights into the relative importance of features and their impact on the dataset.'}
d_allVisFigInfo['fig17']={'text':'This figure portrays the distribution of the most critical features through the utilization of histograms and scatter plots.'}
d_allVisFigInfo['fig18']={'text':'This graph illustrates the features that exert a significant influence on the prediction of the current instance, along with their corresponding Shapley values.<br>The features are determined based on the instance number specified by the user in the software window and the selected classifier.'}
d_allVisFigInfo['fig19']={'text':'This study utilizes heat maps to visually represent the distribution of Shapley values for significant features across all instances. <br>The model\'s output is presented above the heatmap matrix, centered around the explanation\'s base value. <br>Furthermore, the global importance of each model input is depicted as a bar plot on the right-hand side of the visualization.'}
d_allVisFigInfo['fig20']={'text':'The presented figure depicts the SHAP decision plot, providing insights into the rationale behind predictions made by complex models.<ol><li>The x-axis represents the model\'s output, quantified in log odds.</li><li>The y-axis displays the model\'s features, ordered by descending importance as the default arrangement.</li><li>Each observation\'s prediction is visually depicted by a colored line.</li><li>The observations collectively converge at the expected value of the interpreter, located at the bottom of the plot.</li></ol>'}
d_allVisFigInfo['fig21']={'text':'The figure presented represents the Decision curves for a subset of 30 instances, including the first 15 positive examples and the first 15 negative examples. <br>Please note that if the number of test sets is less than 30, the subset size will be reduced to one-tenth of the sample size.'}
d_allVisFigInfo['fig22']={'text':'Waterfall plots are specifically designed for visualizing explanations of individual predictions. <br>They require a single row of an Explanation object as input. In a waterfall plot, the initial value at the bottom represents the expected output of the model. Subsequently, each row demonstrates how the positive (red) or negative (blue) contribution of each feature influences the transition from the expected model output based on the background dataset to the model output for the specific prediction. <br>Please note that the instance displayed corresponds to the number specified by the user through the interface.'}
d_allVisFigInfo['fig23']={'text':'This webpage provides a numerical statistical distribution of the top 20 most significant characteristics.<br>'}